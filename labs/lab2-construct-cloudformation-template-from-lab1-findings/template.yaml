---
AWSTemplateFormatVersion: "2010-09-09"

Description: >
  This template is an attempt to define all IaC services in AWS required for a basic demonstration of processing data 
  incoming via API Gateway and then through a Lambda handler the data is extracted and submitted to Kineses, which in 
  turn will do some very basic translation/conversion before persisting the data in S3. The S3 bucket will send events
  via SNS and SQS to another Lambda function intended as the final data processing operation. The incoming data up to
  the S3 bucket is about capturing the event streams and everything after the S3 bucket is about processing and 
  consuming the event data. Objects are encrypted and when relevant, AWS KMS keys are used.

# Metadata:
#   template metadata

Parameters:
  S3EventBucketParam:
    Type: String
    Description: "The name of the S3 bucket where the incoming event data will be stored. This is the Event store."

# Rules:
#   set of rules

# Mappings:
#   set of mappings

# Conditions:
#   set of conditions

# Transform:
#   set of transforms

Resources:

#######################################################################################################################
###                                                                                                                 ###
###              S3 BUCKET WITH SNS TOPIC AND LAMBDA FOR PROCESSING NEW EVENTS IN THE EVENT STORE (S3)              ###
###                                                                                                                 ###
#######################################################################################################################

  S3EventStoreNotificationDeadLetterQueue:
    Type: AWS::SQS::Queue
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties: 
      MessageRetentionPeriod: 86400
      QueueName: "S3EventStoreNotificationDeadLetterQueue"
      VisibilityTimeout: 60

  S3EventStoreNotificationQueue:
    Type: AWS::SQS::Queue
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties: 
      MessageRetentionPeriod: 86400
      QueueName: "S3EventStoreNotificationQueue"
      RedriveAllowPolicy:
        redrivePermission: "allowAll"
      RedrivePolicy:
        deadLetterTargetArn : !GetAtt S3EventStoreNotificationDeadLetterQueue.Arn
        maxReceiveCount : 3
      VisibilityTimeout: 60

  S3EventStoreNotificationTopic:
    Type: AWS::SNS::Topic
    Properties: 
      DisplayName: "S3EventStoreNotificationTopic"
      FifoTopic: false
      Subscription:
      - Protocol: sqs
        Endpoint: !GetAtt S3EventStoreNotificationQueue.Arn
      TopicName: "S3EventStoreNotification"

  S3EventStoreNotificationPolicy:
    Type: AWS::SNS::TopicPolicy
    Properties:
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: "s3.amazonaws.com"
            Action: sns:Publish
            Resource: !Ref S3EventStoreNotificationTopic
      Topics:
        - !Ref S3EventStoreNotificationTopic

  SnsToSqsPolicy:
    Type: AWS::SQS::QueuePolicy
    Properties:
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Sid: "Allow SNS publish to SQS"
            Effect: Allow
            Principal:
              Service: "sns.amazonaws.com"
            Resource: !GetAtt S3EventStoreNotificationQueue.Arn
            Action: SQS:SendMessage
            Condition:
              ArnEquals:
                aws:SourceArn: !Ref S3EventStoreNotificationTopic
      Queues:
      - Ref: S3EventStoreNotificationQueue

  S3EventStoreBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain
    Properties: 
      AccessControl: "Private"
      BucketName: !Ref S3EventBucketParam
      LifecycleConfiguration: 
        Rules: 
        - AbortIncompleteMultipartUpload: 
            DaysAfterInitiation: 1
          Id: !Sub "${S3EventBucketParam}-archive-lifecycle-01"
          Status: "Enabled"
          Transitions: 
          - StorageClass: "GLACIER"
            TransitionInDays: 7
          - StorageClass: "DEEP_ARCHIVE"  # Days' in the 'Transition' action for StorageClass 'DEEP_ARCHIVE' for filter must be 90 days more than 'Transition' action for StorageClass 'GLACIER' 
            TransitionInDays: 97
      NotificationConfiguration: 
        TopicConfigurations: 
        - Event: "s3:ObjectCreated:*"   # See https://docs.aws.amazon.com/AmazonS3/latest/userguide/notification-how-to-event-types-and-destinations.html#supported-notification-event-types
          Topic: !Ref S3EventStoreNotificationTopic
      Tags: 
      - Key: Purpose
        Value: EventStore

  EventMockProcessingLambdaFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Sid: "EventMockProcessingLambdaFunctionRoleAssumeRolePolicyDocument"
          Effect: "Allow"
          Principal:
            Service: "lambda.amazonaws.com"
          Action: "sts:AssumeRole"
      Description: "Lambda role EventMockProcessingLambdaFunction"
      Policies:
      - PolicyName: EventMockProcessingLambdaFunctionPolicy01
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: "Allow"
            Action:
            - "logs:CreateLogGroup"
            - "logs:CreateLogStream"
            - "logs:PutLogEvents"
            Resource: arn:aws:logs:*:*:*
      - PolicyName: EventMockProcessingLambdaFunctionPolicy02
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: "Allow"
            Action:
            - "sqs:ReceiveMessage"
            - "sqs:DeleteMessage"
            - "sqs:GetQueueAttributes"
            - "sqs:ChangeMessageVisibility"
            Resource: !GetAtt S3EventStoreNotificationQueue.Arn
      RoleName: EventMockProcessingLambdaFunctionRole

  EventMockProcessingLambdaFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName:
        Fn::Sub:
        -  "/aws/lambda/${functionRef}"
        - functionRef: !Ref EventMockProcessingLambdaFunction
      RetentionInDays: 7

  EventMockProcessingLambdaFunction:
    Type: AWS::Lambda::Function
    Properties: 
      Architectures: 
      - "arm64"
      Code: 
        ZipFile: |
          import json
          import logging
          import traceback
          logger = logging.getLogger()
          logger.setLevel(logging.DEBUG)
          def lambda_handler(event, context):
              logger.debug('event={}'.format(event))
              return "ok"
      Description: "Function to process our events from S3. This function basically just logs the messages - no actual processing is done. Typically this function will look at the event and route it to an appropriate event handler via SNS."
      FunctionName: "EventMockProcessingLambdaFunction"
      Handler: "index.lambda_handler"
      MemorySize: 128
      Role: !GetAtt EventMockProcessingLambdaFunctionRole.Arn
      Runtime: "python3.8"
      Timeout: 30

  EventMockProcessingLambdaFunctionEventSourceMapping:
    Type: AWS::Lambda::EventSourceMapping
    Properties:
      BatchSize: 10
      Enabled: true
      EventSourceArn: !GetAtt S3EventStoreNotificationQueue.Arn
      FunctionName: !GetAtt EventMockProcessingLambdaFunction.Arn


#######################################################################################################################
###                                                                                                                 ###
###                                           API GATEWAY LAMBDA FUNCTIONS                                          ###
###                                                                                                                 ###
#######################################################################################################################

  ApiTest01EventLambdaFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Sid: "ApiTest01EventLambdaFunctionRoleAssumeRolePolicyDocument"
          Effect: "Allow"
          Principal:
            Service: "lambda.amazonaws.com"
          Action: "sts:AssumeRole"
      Description: "Lambda role ApiTest01EventLambdaFunction"
      Policies:
      - PolicyName: ApiTest01EventLambdaFunctionPolicy01
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: "Allow"
            Action:
            - "logs:CreateLogGroup"
            - "logs:CreateLogStream"
            - "logs:PutLogEvents"
            Resource: arn:aws:logs:*:*:*
      - PolicyName: ApiTest01EventLambdaFunctionPolicy02
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - kinesis:PutRecord
            - kinesis:PutRecords
            Resource: !Sub arn:${AWS::Partition}:kinesis:*:${AWS::AccountId}:stream/*
      RoleName: ApiTest01EventLambdaFunctionRole

  ApiTest01EventLambdaFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName:
        Fn::Sub:
        -  "/aws/lambda/${functionRef}"
        - functionRef: !Ref ApiTest01EventLambdaFunction
      RetentionInDays: 7

  ApiTest01EventLambdaFunction:
    Type: AWS::Lambda::Function
    Properties: 
      Architectures: 
      - "arm64"
      Environment:
          Variables: 
            TARGET_STREAM_NAME : not-set  # TODO - set the name to the Kinesis stream name still to be defined
      Code: 
        ZipFile: |
          import json
          import logging
          import boto3
          import hashlib
          import traceback
          import os
          logger = logging.getLogger()
          logger.setLevel(logging.DEBUG)
          def lambda_handler(event, context):
              logger.debug('event={}'.format(event))
              client = boto3.client('kinesis')
              incoming_data = dict()
              incoming_data['amazonTraceId'] = event['headers']['X-Amzn-Trace-Id']
              incoming_data['numberOfFields'] = 0
              incoming_data['fieldNames'] = ""
              try:
                  body_data = json.loads(event['body'])
                  keys = list(body_data.keys())
                  incoming_data['numberOfFields'] = len(keys)
                  incoming_data['fieldNames'] = ",".join(keys)
                  response = client.put_record(
                      StreamName='{}'.format(os.getenv('TARGET_STREAM_NAME', 'not-set')),
                      Data='{}'.format(json.dumps(incoming_data)).encode('utf-8'),
                      PartitionKey=hashlib.md5('{}'.format(json.dumps(incoming_data)).encode('utf-8')).hexdigest()
                  )
                  logger.debug('response={}'.format(response))
              except:
                  logger.error('EXCEPTION: {}'.format(traceback.format_exc()))
              result = dict()
              return_object = {
                  'statusCode': 201,
                  'headers': {
                      'x-custom-header' : 'my custom header value',
                      'content-type': 'application/json',
                  },
                  'body': result,
                  'isBase64Encoded': False,
              }
              result['message'] = 'ok'
              return_object['body'] = json.dumps(result)
              return return_object
      Description: "Handle the test event and emit event data to AWS Kinesis"
      FunctionName: "ApiTest01EventLambdaFunction"
      Handler: "index.lambda_handler"
      MemorySize: 128
      Role: !GetAtt ApiTest01EventLambdaFunctionRole.Arn
      Runtime: "python3.8"
      Timeout: 30


#######################################################################################################################
###                                                                                                                 ###
###                     ENTRY POINT FOR EVENTS - API HTTP GATEWAY WITH PROXY TO LAMBDA FUNCTION                     ###
###                                                                                                                 ###
#######################################################################################################################

  PublicEventApiGateway:
    Type: AWS::ApiGatewayV2::Api
    Properties: 
      CorsConfiguration:
        AllowCredentials: true
        AllowHeaders: 
        - "Content-Type"
        - "X-Amz-Date"
        - "Authorization"
        - "X-Api-Key"
        - "X-Amz-Security-Token"
        AllowMethods: 
        - OPTIONS
        - GET
        - POST
        - PUT
        - DELETE
        AllowOrigins: 
        - "http://localhost"
        - "http://localhost:9000"
        ExposeHeaders: 
        - "Date"
        - "x-api-id"
        MaxAge: 86400
      Description: "The Internet facing HTTP API for publishing events from external sources, like web sites"
      DisableExecuteApiEndpoint: false  # For production, this will typically be disabled/true to force clients to use the custom domain
      Name: "public-events"
      ProtocolType: "HTTP"
      Version: "v1"

  PublicApiEVentRouteTest01:
    Type: AWS::ApiGatewayV2::Route
    Properties: 
      ApiId: !Ref PublicEventApiGateway
      ApiKeyRequired: false
      OperationName: "test-public-event-operation"
      RouteKey: "POST /test01"
      Target: 
        Fn::Join:
        - /
        - - integrations
          - !Ref PublicApiEventIntegrationTest01

  PublicApiEventIntegrationTest01:  # NOTE: The maximum (and default) timeout is 30 seconds
    Type: AWS::ApiGatewayV2::Integration
    Properties: 
      ApiId: !Ref PublicEventApiGateway
      Description: "Lambda Integration"
      IntegrationType: AWS_PROXY
      IntegrationUri: 
        Fn::Sub: 
        - "arn:${AWS::Partition}:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${functionArn}/invocations"
        - functionArn: !GetAtt ApiTest01EventLambdaFunction.Arn
      IntegrationMethod: POST
      PayloadFormatVersion: '2.0'

  PublicEventApiGatewaySandboxStageDeployment:
    Type: AWS::ApiGatewayV2::Deployment
    DependsOn: PublicApiEVentRouteTest01
    Properties: 
      ApiId: !Ref PublicEventApiGateway
      Description: "Sandbox Deployment"
      # StageName: "sandbox"

  PublicEventApiGatewaySandboxStageLogs:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      RetentionInDays: 90

  PublicEventApiGatewaySandboxStage:
    Type: AWS::ApiGatewayV2::Stage
    Properties: 
      AccessLogSettings: 
        DestinationArn: !GetAtt PublicEventApiGatewaySandboxStageLogs.Arn
        Format: $context.stage $context.integrationErrorMessage $context.identity.sourceIp $context.identity.caller $context.identity.user [$context.requestTime] "$context.httpMethod $context.resourcePath $context.protocol" $context.status $context.responseLength $context.requestId $context.extendedRequestId
      ApiId: !Ref PublicEventApiGateway
      AutoDeploy: true
      DeploymentId: !Ref PublicEventApiGatewaySandboxStageDeployment
      Description: "Testing Stage - Not for Production"
      StageName: "sandbox"
      DefaultRouteSettings:
        DetailedMetricsEnabled: true
        LoggingLevel: INFO
        DataTraceEnabled: false
        ThrottlingBurstLimit: 10
        ThrottlingRateLimit: 10


Outputs:

  S3EventStoreBucketDomainName:
    Description: "Bucket DomainName"
    Value: !GetAtt S3EventStoreBucket.DomainName
    Export:
      Name: !Sub "${AWS::StackName}-S3EventStoreBucketDomainName"

  PublicEventApiGatewayApiEndpoint:
    Description: "The default endpoint for API PublicEventApiGateway"
    Value: !GetAtt PublicEventApiGateway.ApiEndpoint
    Export:
      Name: !Sub "${AWS::StackName}-PublicEventApiGatewayApiEndpoint"
