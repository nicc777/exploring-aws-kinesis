---
AWSTemplateFormatVersion: "2010-09-09"

Description: >
  A basic Lambda function that expects the Lambda function source to be a ZIPPED file in S3

# Metadata:
#   template metadata

Parameters:
  S3SourceBucketParam:
    Type: String
    Description: "The S3 bucket name containing the Lambda function ZIP file"
  S3EventBucketParam:
    Type: String
    Description: "The name of the S3 bucket where the incoming event data will be stored. This is the Event store."
  Test01RouteKey:
    Type: String
    Description: "The API Route Path"
    Default: "test01"

# Rules:
#   set of rules

# Mappings:
#   set of mappings

# Conditions:
#   set of conditions

# Transform:
#   set of transforms

Resources:


#######################################################################################################################
###                                                                                                                 ###
###                                           API GATEWAY LAMBDA FUNCTIONS                                          ###
###                                                                                                                 ###
#######################################################################################################################

  ListEmployeeIdsLambdaFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Sid: "ListEmployeeIdsLambdaFunctionRoleAssumeRolePolicyDocument"
          Effect: "Allow"
          Principal:
            Service: "lambda.amazonaws.com"
          Action: "sts:AssumeRole"
      Description: "Lambda role ListEmployeeIdsLambdaFunction"
      Policies:
      - PolicyName: ListEmployeeIdsLambdaFunctionPolicy01
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: "Allow"
            Action:
            - "logs:CreateLogGroup"
            - "logs:CreateLogStream"
            - "logs:PutLogEvents"
            Resource: !Sub "arn:${AWS::Partition}:logs:*:*:*""
      - PolicyName: ListEmployeeIdsLambdaFunctionPolicy02
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Effect: Allow
            Action:
            - "dynamodb:Scan"
            - "dynamodb:Query"
            Resource:
            - Fn::Sub 
              - "arn:${AWS::Partition}:dynamodb:${AWS::Region}:${AWS::AccountId}:table/${TableName}"
              - TableName:
                  Fn::ImportValue: 
                    Fn::Sub: 
                    - "${DynamoDbStackName}-AccessCardAppTableName"
                    - DynamoDbStackName: !ImportValue "Lab3DynamoDbStackName"
            - "arn:${AWS::Partition}:dynamodb:*:${AWS::AccountId}:table/*/index/*"
      RoleName: ListEmployeeIdsLambdaFunctionRole

  ListEmployeeIdsLambdaFunctionLogGroup:
    Type: AWS::Logs::LogGroup
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      LogGroupName:
        Fn::Sub:
        -  "/aws/lambda/${functionRef}"
        - functionRef: !Ref ListEmployeeIdsLambdaFunction
      RetentionInDays: 7

  ListEmployeeIdsLambdaFunction:
    Type: AWS::Lambda::Function
    Properties: 
      Architectures: 
      - "arm64"
      Code: 
        S3Bucket: !Ref S3SourceBucketParam
        S3Key: "list_employee_ids_lambda_function.zip"
      Description: "Handle the test event and emit event data to AWS Kinesis"
      FunctionName: "ListEmployeeIdsLambdaFunction"
      Handler: "list_employee_ids.handler"
      MemorySize: 128
      Role: !GetAtt ListEmployeeIdsLambdaFunctionRole.Arn
      Runtime: "python3.8"
      Timeout: 30


Outputs:

  ListEmployeeIdsLambdaFunctionArn:
    Description: "ARN for ListEmployeeIdsLambdaFunction"
    Value: !GetAtt ListEmployeeIdsLambdaFunction.Arn
    Export:
      Name: !Sub "${AWS::StackName}-ListEmployeeIdsLambdaFunctionArn"

  StackName:
    Description: "Lambda Functions Stack Name"
    Value: !Sub ${AWS::StackName}
    Export:
      Name: !Sub "Lab3LambdaFunctionsStackName"
